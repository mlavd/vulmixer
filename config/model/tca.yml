type: fire

max_seq_length: &max_seq_length 1024
batch_size: 128

input:
  embeddings: microsoft/graphcodebert-base
  embedding_size: &embedding_size 768
  truncate: False
  normalize: False

bottleneck:
  type: linear
  embedding_size: *embedding_size
  hidden_dim: &hidden_dim 128

mixers:
  - token:
      type: tca
      hidden_dim: *hidden_dim
      max_seq_length: *max_seq_length
      num_heads: 16
      keep_prob: 0.8
      kernel_size: [ 5, 3, 3, 3 ]
      dilation: [ 1, 1, 1, 1 ]
      padding: [ 2, 1, 1, 1 ]
      activation: gelu
    feature:
      type: mlp
      hidden_dim: *hidden_dim
      inner_dim: *hidden_dim
      activation: gelu
      dropout: 0.5
    depth: 4
    hidden_dim: *hidden_dim

classifier:
  type: linear
  pooling: max
  hidden_dim: *hidden_dim
  num_classes: 2

optimizer:
  lr: 5e-4
  betas: [0.9, 0.999]
  eps: 1e-8
